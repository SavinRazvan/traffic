{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 17:10:18.414390: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 17:10:18.417505: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 17:10:18.425708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 17:10:18.439286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 17:10:18.443384: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 17:10:18.453287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 17:10:19.150497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Suppress TensorFlow log messages to keep the output clean\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Set TensorFlow logger to only show error messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "EPOCHS          = 100           # Number of training epochs\n",
    "IMG_WIDTH       = 30            # Width of the input images\n",
    "IMG_HEIGHT      = 30            # Height of the input images\n",
    "NUM_CATEGORIES  = 43            # Number of categories (classes) in the dataset\n",
    "TEST_SIZE       = 0.4           # Proportion of the dataset to include in the test split\n",
    "\n",
    "data_dir    = 'data/gtsrb'                  # Directory containing the dataset\n",
    "model_path  = 'models/best_model.keras'     # Path to save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load images from a directory, preprocess them by resizing and normalizing, and return the images and their labels.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing subdirectories of images. Each subdirectory should be named \n",
    "                    with an integer label and contain the corresponding images.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of preprocessed images.\n",
    "    np.ndarray: Array of labels corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over each folder in the data directory\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        \n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Convert folder name to integer label\n",
    "        label = int(folder)\n",
    "        \n",
    "        # Iterate over each file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Check if the file is an image\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm')):\n",
    "                image = cv2.imread(file_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    # Resize the image to the desired dimensions\n",
    "                    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    preprocessed_image = resized_image / 255.0\n",
    "                    \n",
    "                    # Append the preprocessed image and label to the lists\n",
    "                    images.append(preprocessed_image)\n",
    "                    labels.append(label)\n",
    "\n",
    "    print(f\"Total images loaded: {len(images)}, and number of labels: {len(set(labels))}\")\n",
    "    print(f\"Unique labels: {set(labels)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess a single image by resizing it to the desired dimensions, normalizing the pixel values,\n",
    "    and adding a batch dimension.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The preprocessed image with an added batch dimension.\n",
    "    \"\"\"\n",
    "    # Resize the image to the desired dimensions\n",
    "    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    # Normalize the image by scaling pixel values to the range [0, 1]\n",
    "    preprocessed_image = resized_image / 255.0\n",
    "    \n",
    "    # Add a batch dimension to the image\n",
    "    return np.expand_dims(preprocessed_image, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image):\n",
    "    \"\"\"\n",
    "    Predict the class of a single preprocessed image using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    model (keras.Model): The trained model used for making the prediction.\n",
    "    image (np.ndarray): The preprocessed image to predict.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class label for the input image.\n",
    "    \"\"\"\n",
    "    # Use the model to predict the class probabilities of the input image\n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    # Return the index of the class with the highest probability\n",
    "    return np.argmax(prediction, axis=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a trained model from the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    model_path (str): Path to the saved model file.\n",
    "\n",
    "    Returns:\n",
    "    keras.Model: The loaded trained model.\n",
    "    \"\"\"\n",
    "    # Load and return the trained model from the specified path\n",
    "    return keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model.\n",
    "\n",
    "    The model architecture includes:\n",
    "    - Three convolutional layers with increasing filter sizes and ReLU activation.\n",
    "    - Max pooling layers after each convolutional layer to reduce spatial dimensions.\n",
    "    - Batch normalization layers to stabilize and accelerate training.\n",
    "    - A flatten layer to convert the 3D outputs to 1D vectors.\n",
    "    - A dense (fully connected) layer with ReLU activation and L2 regularization.\n",
    "    - A dropout layer to prevent overfitting.\n",
    "    - An output dense layer with softmax activation for classification into NUM_CATEGORIES classes.\n",
    "\n",
    "    Returns:\n",
    "        model (tf.keras.Model): Compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input layer with shape (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "\n",
    "        # First convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size to reduce spatial dimensions\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization to stabilize and speed up training\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Second convolutional layer with 128 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Third convolutional layer with 256 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Flatten layer to convert 3D outputs to 1D vectors\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # Dense layer with 512 units, ReLU activation, and L2 regularization\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        # Dropout layer with 0.5 rate to prevent overfitting\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Output layer with NUM_CATEGORIES units and softmax activation for classification\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metrics\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['categorical_accuracy'],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training history of the model, including accuracy and loss for both training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "        history (tf.keras.callbacks.History): History object returned by the fit method of a Keras model. It contains\n",
    "                                              training and validation loss and accuracy for each epoch.\n",
    "\n",
    "    The function creates two subplots:\n",
    "    - The first subplot shows the accuracy over epochs for both training and validation data.\n",
    "    - The second subplot shows the loss over epochs for both training and validation data.\n",
    "    \"\"\"\n",
    "     # Set the figure size for the plots\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot accuracy over epochs\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['categorical_accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], label='Validation')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Plot loss over epochs\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_results(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset and print the final loss and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The trained Keras model to evaluate.\n",
    "        x_test (numpy.ndarray): The test data, features.\n",
    "        y_test (numpy.ndarray): The test data, labels.\n",
    "\n",
    "    The function evaluates the model using the test data and prints the final loss and accuracy.\n",
    "    \"\"\"\n",
    "    # Evaluate the model on the test data and obtain the loss and accuracy\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "    # Print the final loss and accuracy with four decimal places\n",
    "    print(f\"Final loss: {loss:.2f}\")\n",
    "    print(f\"Final accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to stop training when a specified condition is met.\n",
    "\n",
    "    This callback stops training if the validation accuracy reaches 100%.\n",
    "\n",
    "    Methods:\n",
    "        on_epoch_end(epoch, logs=None): Checks validation accuracy at the end of each epoch and stops training if it reaches 100%.\n",
    "    \"\"\"\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch during training.\n",
    "\n",
    "        Parameters:\n",
    "            epoch (int): The index of the epoch.\n",
    "            logs (dict, optional): Contains metrics and their values for the epoch.\n",
    "\n",
    "        If the validation accuracy (`val_categorical_accuracy`) reaches 100%, training is stopped.\n",
    "        \"\"\"\n",
    "        if logs.get('val_categorical_accuracy') == 1.0:\n",
    "            print(f\"Reached 100% accuracy so stopping training!\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 26425, and number of labels: 43\n",
      "Unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722348622.987361   11072 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-30 17:10:22.987982: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  2/496\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 51ms/step - categorical_accuracy: 0.0312 - loss: 5.7994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razvansavin/miniconda3/envs/.conda/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.3656 - loss: 3.2446\n",
      "Epoch 1: val_loss improved from inf to 2.46823, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 45ms/step - categorical_accuracy: 0.3660 - loss: 3.2426 - val_categorical_accuracy: 0.4925 - val_loss: 2.4682 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.8596 - loss: 1.0298\n",
      "Epoch 2: val_loss improved from 2.46823 to 0.59920, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.8597 - loss: 1.0296 - val_categorical_accuracy: 0.9648 - val_loss: 0.5992 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9380 - loss: 0.6602\n",
      "Epoch 3: val_loss improved from 0.59920 to 0.47450, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - categorical_accuracy: 0.9380 - loss: 0.6600 - val_categorical_accuracy: 0.9678 - val_loss: 0.4745 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9551 - loss: 0.4969\n",
      "Epoch 4: val_loss improved from 0.47450 to 0.34111, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - categorical_accuracy: 0.9551 - loss: 0.4968 - val_categorical_accuracy: 0.9816 - val_loss: 0.3411 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.9609 - loss: 0.4049\n",
      "Epoch 5: val_loss improved from 0.34111 to 0.32492, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - categorical_accuracy: 0.9609 - loss: 0.4049 - val_categorical_accuracy: 0.9798 - val_loss: 0.3249 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.9671 - loss: 0.3566\n",
      "Epoch 6: val_loss improved from 0.32492 to 0.32462, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - categorical_accuracy: 0.9671 - loss: 0.3566 - val_categorical_accuracy: 0.9738 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.9735 - loss: 0.3191\n",
      "Epoch 7: val_loss improved from 0.32462 to 0.27263, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - categorical_accuracy: 0.9735 - loss: 0.3191 - val_categorical_accuracy: 0.9842 - val_loss: 0.2726 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9731 - loss: 0.3125\n",
      "Epoch 8: val_loss did not improve from 0.27263\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - categorical_accuracy: 0.9731 - loss: 0.3125 - val_categorical_accuracy: 0.9792 - val_loss: 0.2926 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9718 - loss: 0.3247\n",
      "Epoch 9: val_loss did not improve from 0.27263\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9718 - loss: 0.3247 - val_categorical_accuracy: 0.9669 - val_loss: 0.3608 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9621 - loss: 0.3930\n",
      "Epoch 10: val_loss did not improve from 0.27263\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9621 - loss: 0.3930 - val_categorical_accuracy: 0.9854 - val_loss: 0.3180 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9842 - loss: 0.3163\n",
      "Epoch 11: val_loss improved from 0.27263 to 0.25488, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9843 - loss: 0.3162 - val_categorical_accuracy: 0.9982 - val_loss: 0.2549 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9930 - loss: 0.2679\n",
      "Epoch 12: val_loss improved from 0.25488 to 0.22934, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9930 - loss: 0.2679 - val_categorical_accuracy: 0.9989 - val_loss: 0.2293 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9950 - loss: 0.2379\n",
      "Epoch 13: val_loss improved from 0.22934 to 0.20437, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9950 - loss: 0.2379 - val_categorical_accuracy: 0.9990 - val_loss: 0.2044 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9958 - loss: 0.2114\n",
      "Epoch 14: val_loss improved from 0.20437 to 0.17836, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9958 - loss: 0.2114 - val_categorical_accuracy: 0.9992 - val_loss: 0.1784 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9967 - loss: 0.1821\n",
      "Epoch 15: val_loss improved from 0.17836 to 0.15405, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9967 - loss: 0.1821 - val_categorical_accuracy: 0.9992 - val_loss: 0.1541 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9959 - loss: 0.1601\n",
      "Epoch 16: val_loss improved from 0.15405 to 0.13188, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9959 - loss: 0.1601 - val_categorical_accuracy: 0.9991 - val_loss: 0.1319 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.9972 - loss: 0.1356\n",
      "Epoch 17: val_loss improved from 0.13188 to 0.11158, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - categorical_accuracy: 0.9972 - loss: 0.1356 - val_categorical_accuracy: 0.9994 - val_loss: 0.1116 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9980 - loss: 0.1144\n",
      "Epoch 18: val_loss improved from 0.11158 to 0.09360, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9980 - loss: 0.1144 - val_categorical_accuracy: 0.9995 - val_loss: 0.0936 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9977 - loss: 0.0978\n",
      "Epoch 19: val_loss improved from 0.09360 to 0.07876, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9977 - loss: 0.0978 - val_categorical_accuracy: 0.9996 - val_loss: 0.0788 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9978 - loss: 0.0820\n",
      "Epoch 20: val_loss improved from 0.07876 to 0.06633, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9978 - loss: 0.0820 - val_categorical_accuracy: 0.9996 - val_loss: 0.0663 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9987 - loss: 0.0706\n",
      "Epoch 21: val_loss improved from 0.06633 to 0.05690, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9987 - loss: 0.0706 - val_categorical_accuracy: 0.9995 - val_loss: 0.0569 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9978 - loss: 0.0635\n",
      "Epoch 22: val_loss improved from 0.05690 to 0.05017, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9978 - loss: 0.0635 - val_categorical_accuracy: 0.9994 - val_loss: 0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9990 - loss: 0.0541\n",
      "Epoch 23: val_loss improved from 0.05017 to 0.04366, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9990 - loss: 0.0541 - val_categorical_accuracy: 0.9996 - val_loss: 0.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9979 - loss: 0.0513\n",
      "Epoch 24: val_loss improved from 0.04366 to 0.03957, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9979 - loss: 0.0513 - val_categorical_accuracy: 0.9996 - val_loss: 0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9983 - loss: 0.0455\n",
      "Epoch 25: val_loss improved from 0.03957 to 0.03624, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9983 - loss: 0.0455 - val_categorical_accuracy: 0.9995 - val_loss: 0.0362 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9989 - loss: 0.0405\n",
      "Epoch 26: val_loss improved from 0.03624 to 0.03242, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9989 - loss: 0.0405 - val_categorical_accuracy: 0.9997 - val_loss: 0.0324 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.9992 - loss: 0.0359\n",
      "Epoch 27: val_loss improved from 0.03242 to 0.03069, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - categorical_accuracy: 0.9992 - loss: 0.0359 - val_categorical_accuracy: 0.9996 - val_loss: 0.0307 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9989 - loss: 0.0341\n",
      "Epoch 28: val_loss improved from 0.03069 to 0.02834, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9989 - loss: 0.0341 - val_categorical_accuracy: 0.9991 - val_loss: 0.0283 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9987 - loss: 0.0342\n",
      "Epoch 29: val_loss improved from 0.02834 to 0.02714, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9987 - loss: 0.0342 - val_categorical_accuracy: 0.9994 - val_loss: 0.0271 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9988 - loss: 0.0313\n",
      "Epoch 30: val_loss improved from 0.02714 to 0.02584, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9988 - loss: 0.0313 - val_categorical_accuracy: 0.9994 - val_loss: 0.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.9982 - loss: 0.0308\n",
      "Epoch 31: val_loss improved from 0.02584 to 0.02424, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - categorical_accuracy: 0.9982 - loss: 0.0308 - val_categorical_accuracy: 0.9996 - val_loss: 0.0242 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.9989 - loss: 0.0289\n",
      "Epoch 32: val_loss improved from 0.02424 to 0.02294, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - categorical_accuracy: 0.9989 - loss: 0.0289 - val_categorical_accuracy: 0.9995 - val_loss: 0.0229 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.9989 - loss: 0.0267\n",
      "Epoch 33: val_loss improved from 0.02294 to 0.02237, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - categorical_accuracy: 0.9989 - loss: 0.0267 - val_categorical_accuracy: 0.9996 - val_loss: 0.0224 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m495/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.9992 - loss: 0.0265\n",
      "Epoch 34: val_loss improved from 0.02237 to 0.02204, saving model to models/best_model.keras\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - categorical_accuracy: 0.9992 - loss: 0.0265 - val_categorical_accuracy: 0.9996 - val_loss: 0.0220 - learning_rate: 1.0000e-04\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 - 2s - 7ms/step - categorical_accuracy: 0.9992 - loss: 0.1784\n",
      "Final loss: 0.18\n",
      "Final accuracy: 99.92%\n"
     ]
    }
   ],
   "source": [
    "def main(data_dir, model_path):\n",
    "    \"\"\"\n",
    "    Main function to load data, preprocess it, train a model, and evaluate the results.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing the dataset.\n",
    "    model_path (str): Path to save the trained model.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the data\n",
    "    images, labels = load_and_preprocess_data(data_dir)\n",
    "    \n",
    "    # Check if images or labels are empty\n",
    "    if len(images) == 0 or len(labels) == 0:\n",
    "        print(\"No images or labels found. Please check the data directory.\")\n",
    "        return\n",
    "\n",
    "    # Convert labels to categorical format\n",
    "    labels = tf.keras.utils.to_categorical(labels, NUM_CATEGORIES)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Create an image data generator for data augmentation\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Get the model\n",
    "    model = get_model()\n",
    "\n",
    "    # Define callbacks for training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1\n",
    "    )\n",
    "\n",
    "    # Early stopping callback to prevent overfitting by stopping training early if the validation accuracy does not improve\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',  # Monitor the validation categorical accuracy\n",
    "        min_delta=0.001,                     # Minimum change to qualify as an improvement\n",
    "        patience=20,                         # Number of epochs with no improvement after which training will be stopped\n",
    "        mode='max',                          # Stop when the quantity monitored has stopped increasing\n",
    "        verbose=1,                           # Print messages when early stopping is triggered\n",
    "        restore_best_weights=True            # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler callback to reduce the learning rate when the validation loss plateaus\n",
    "    lr_scheduler_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',                  # Monitor the validation loss\n",
    "        factor=0.1,                          # Factor by which the learning rate will be reduced\n",
    "        patience=3,                          # Number of epochs with no improvement after which learning rate will be reduced\n",
    "        verbose=1,                           # Print messages when the learning rate is reduced\n",
    "        min_delta=0.001,                     # Minimum change to qualify as an improvement\n",
    "        cooldown=1,                          # Number of epochs to wait before resuming normal operation after the learning rate has been reduced\n",
    "        min_lr=1e-6                          # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    # Custom callback for additional functionality (defined elsewhere in the code)\n",
    "    custom_callback = CustomCallback()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=32), \n",
    "        epochs=EPOCHS, \n",
    "        validation_data=(x_test, y_test), \n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_scheduler_callback, custom_callback]\n",
    "    )\n",
    "\n",
    "    # Plot the training history\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Print the final results\n",
    "    print_final_results(model, x_test, y_test)\n",
    "\n",
    "# Call the main function with the appropriate data directory and model path\n",
    "main(data_dir, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "5 Predictions for each label, used files that I moved in other folder to see how models perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load images from directory: 'data/gtsrb-test-files'.\n",
      "Total images loaded: 215\n",
      "Unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "Correct predictions: 215\n",
      "Incorrect predictions: 0\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "IMG_PREDICTIONS_PER_FOLDER = 5\n",
    "\n",
    "# Moved 5 files (each category) from the GTSRB dataset in another folder to use trained model on them to see if performs well\n",
    "data_dir = 'data/gtsrb-test-files' \n",
    "\n",
    "def load_and_preprocess_data(data_dir, num_images_per_label=1):\n",
    "    \"\"\"\n",
    "    Load images from a directory, preprocess them by resizing and normalizing, and return the images and their labels.\n",
    "    Limits the number of images per label to a specified number.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing subdirectories of images. Each subdirectory should be named \n",
    "                    with an integer label and contain the corresponding images.\n",
    "    num_images_per_label (int): The maximum number of images to load per label. Default is 1 (minimum).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of preprocessed images.\n",
    "    np.ndarray: Array of labels corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_count = defaultdict(int)\n",
    "\n",
    "    # Iterate over each folder in the data directory\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        \n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Convert folder name to integer label\n",
    "        label = int(folder)\n",
    "        \n",
    "        # Iterate over each file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Stop if the number of images for this label reaches the limit\n",
    "            if label_count[label] >= num_images_per_label:\n",
    "                break\n",
    "\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Check if the file is an image\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm')):\n",
    "                image = cv2.imread(file_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    # Resize the image to the desired dimensions\n",
    "                    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    preprocessed_image = resized_image / 255.0\n",
    "                    \n",
    "                    # Append the preprocessed image and label to the lists\n",
    "                    images.append(preprocessed_image)\n",
    "                    labels.append(label)\n",
    "                    label_count[label] += 1\n",
    "\n",
    "    print(f\"Load images from directory: '{data_dir}'.\")\n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    print(f\"Unique labels: {set(labels)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load and preprocess the entire dataset with a limit of 10 images per label\n",
    "images, true_labels = load_and_preprocess_data(data_dir, num_images_per_label=IMG_PREDICTIONS_PER_FOLDER)\n",
    "\n",
    "# Initialize counters for correct and incorrect predictions\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "# Make predictions on the dataset\n",
    "for i, image in enumerate(images):\n",
    "    preprocessed_image = np.expand_dims(image, axis=0)  # Already normalized during loading\n",
    "    prediction = predict_image(model, preprocessed_image)\n",
    "    if prediction == true_labels[i]:\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        incorrect_predictions += 1\n",
    "    print(f\"True class: {true_labels[i]} - Predicted class: {prediction}\")\n",
    "\n",
    "# Print the count of correct and incorrect predictions\n",
    "total_predictions = correct_predictions + incorrect_predictions\n",
    "accuracy_percentage = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Incorrect predictions: {incorrect_predictions}\")\n",
    "print(f\"Accuracy: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
