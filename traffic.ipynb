{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Sign Classification with TensorFlow\n",
    "\n",
    "This project is part of CS50's Introduction to Artificial Intelligence with Python. The objective is to create a neural network capable of classifying traffic signs from images using the German Traffic Sign Recognition Benchmark (GTSRB) dataset.\n",
    "\n",
    "#### Features\n",
    "1. **Data Preparation**: \n",
    "   - Images are preprocessed using OpenCV.\n",
    "   - Data augmentation techniques are applied to increase the diversity of the training data.\n",
    "\n",
    "2. **Model Development**: \n",
    "   - A TensorFlow-based neural network is built and trained.\n",
    "   - Model architecture includes convolutional layers for feature extraction and fully connected layers for classification.\n",
    "\n",
    "3. **Evaluation**: \n",
    "   - Model performance is validated on a test dataset.\n",
    "   - The model is used to make predictions on unseen data.\n",
    "\n",
    "4. **Documentation**: \n",
    "   - Detailed documentation of the experimentation process is provided.\n",
    "\n",
    "#### Dataset\n",
    "The GTSRB dataset can be downloaded from the following links:\n",
    "- [GTSRB - Training and Testing Dataset](https://cdn.cs50.net/ai/2023/x/projects/5/gtsrb.zip)\n",
    "- [GTSRB Small - Training and Testing Dataset](https://cdn.cs50.net/ai/2023/x/projects/5/gtsrb-small.zip)\n",
    "\n",
    "#### Code Modifications\n",
    "The current code includes modifications for improved performance and additional features.\n",
    "\n",
    "#### Additional Resources\n",
    "For more details, visit the [project page](https://cs50.harvard.edu/ai/2024/projects/5/traffic/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 19:15:49.810003: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 19:15:49.817917: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 19:15:49.833276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 19:15:49.853181: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 19:15:49.858568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 19:15:49.880717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 19:15:50.612960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "EPOCHS          = 100           # Number of training epochs\n",
    "IMG_WIDTH       = 30            # Width of the input images\n",
    "IMG_HEIGHT      = 30            # Height of the input images\n",
    "NUM_CATEGORIES  = 43            # Number of categories (classes) in the dataset\n",
    "TEST_SIZE       = 0.2           # Proportion of the dataset to include in the test split\n",
    "\n",
    "data_dir    = 'data/gtsrb'                  # Directory containing the dataset\n",
    "model_path  = 'models/best_model.keras'     # Path to save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load images from a directory, preprocess them by resizing and normalizing, and return the images and their labels.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing subdirectories of images. Each subdirectory should be named \n",
    "                    with an integer label and contain the corresponding images.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of preprocessed images.\n",
    "    np.ndarray: Array of labels corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over each folder in the data directory\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        \n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Convert folder name to integer label\n",
    "        label = int(folder)\n",
    "        \n",
    "        # Iterate over each file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Check if the file is an image\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm')):\n",
    "                image = cv2.imread(file_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    # Resize the image to the desired dimensions\n",
    "                    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    preprocessed_image = resized_image / 255.0\n",
    "                    \n",
    "                    # Append the preprocessed image and label to the lists\n",
    "                    images.append(preprocessed_image)\n",
    "                    labels.append(label)\n",
    "\n",
    "    print(f\"Total images loaded: {len(images)}, and number of labels: {len(set(labels))}\")\n",
    "    print(f\"Unique labels: {set(labels)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess a single image by resizing it to the desired dimensions, normalizing the pixel values,\n",
    "    and adding a batch dimension.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The preprocessed image with an added batch dimension.\n",
    "    \"\"\"\n",
    "    # Resize the image to the desired dimensions\n",
    "    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    # Normalize the image by scaling pixel values to the range [0, 1]\n",
    "    preprocessed_image = resized_image / 255.0\n",
    "    \n",
    "    # Add a batch dimension to the image\n",
    "    return np.expand_dims(preprocessed_image, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Custom preprocessing function to apply data augmentation techniques.\n",
    "    \"\"\"\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image):\n",
    "    \"\"\"\n",
    "    Predict the class of a single preprocessed image using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    model (keras.Model): The trained model used for making the prediction.\n",
    "    image (np.ndarray): The preprocessed image to predict.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class label for the input image.\n",
    "    \"\"\"\n",
    "    # Use the model to predict the class probabilities of the input image\n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    # Return the index of the class with the highest probability\n",
    "    return np.argmax(prediction, axis=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a trained model from the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    model_path (str): Path to the saved model file.\n",
    "\n",
    "    Returns:\n",
    "    keras.Model: The loaded trained model.\n",
    "    \"\"\"\n",
    "    # Load and return the trained model from the specified path\n",
    "    return keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model.\n",
    "\n",
    "    The model architecture includes:\n",
    "    - Three convolutional layers with increasing filter sizes and ReLU activation.\n",
    "    - Max pooling layers after each convolutional layer to reduce spatial dimensions.\n",
    "    - Batch normalization layers to stabilize and accelerate training.\n",
    "    - A flatten layer to convert the 3D outputs to 1D vectors.\n",
    "    - A dense (fully connected) layer with ReLU activation and L2 regularization.\n",
    "    - A dropout layer to prevent overfitting.\n",
    "    - An output dense layer with softmax activation for classification into NUM_CATEGORIES classes.\n",
    "\n",
    "    Returns:\n",
    "        model (tf.keras.Model): Compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input layer with shape (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "\n",
    "        # First convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size to reduce spatial dimensions\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization to stabilize and speed up training\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Second convolutional layer with 128 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Third convolutional layer with 256 filters, 3x3 kernel size, and ReLU activation\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "        # Max pooling layer with 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Batch normalization\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # Flatten layer to convert 3D outputs to 1D vectors\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # Dense layer with 512 units, ReLU activation, and L2 regularization\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        # Dropout layer with 0.5 rate to prevent overfitting\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Output layer with NUM_CATEGORIES units and softmax activation for classification\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metrics\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['categorical_accuracy'],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training history of the model, including accuracy and loss for both training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "        history (tf.keras.callbacks.History): History object returned by the fit method of a Keras model. It contains\n",
    "                                              training and validation loss and accuracy for each epoch.\n",
    "\n",
    "    The function creates two subplots:\n",
    "    - The first subplot shows the accuracy over epochs for both training and validation data.\n",
    "    - The second subplot shows the loss over epochs for both training and validation data.\n",
    "    \"\"\"\n",
    "     # Set the figure size for the plots\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot accuracy over epochs\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['categorical_accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], label='Validation')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Plot loss over epochs\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_results(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset and print the final loss and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The trained Keras model to evaluate.\n",
    "        x_test (numpy.ndarray): The test data, features.\n",
    "        y_test (numpy.ndarray): The test data, labels.\n",
    "\n",
    "    The function evaluates the model using the test data and prints the final loss and accuracy.\n",
    "    \"\"\"\n",
    "    # Evaluate the model on the test data and obtain the loss and accuracy\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "    # Print the final loss and accuracy with four decimal places\n",
    "    print(f\"Final loss: {loss:.2f}\")\n",
    "    print(f\"Final accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to stop training when a specified condition is met.\n",
    "\n",
    "    This callback stops training if the validation accuracy reaches 100%.\n",
    "\n",
    "    Methods:\n",
    "        on_epoch_end(epoch, logs=None): Checks validation accuracy at the end of each epoch and stops training if it reaches 100%.\n",
    "    \"\"\"\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch during training.\n",
    "\n",
    "        Parameters:\n",
    "            epoch (int): The index of the epoch.\n",
    "            logs (dict, optional): Contains metrics and their values for the epoch.\n",
    "\n",
    "        If the validation accuracy (`val_categorical_accuracy`) reaches 100%, training is stopped.\n",
    "        \"\"\"\n",
    "        if logs.get('val_categorical_accuracy') == 1.0:\n",
    "            print(f\"Reached 100% accuracy so stopping training!\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 26425, and number of labels: 43\n",
      "Unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722356154.543539   52613 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-30 19:15:54.544117: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razvansavin/miniconda3/envs/.conda/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.3000 - loss: 3.5683\n",
      "Epoch 1: val_loss improved from inf to 1.43414, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 73ms/step - categorical_accuracy: 0.3005 - loss: 3.5654 - val_categorical_accuracy: 0.7031 - val_loss: 1.4341 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - categorical_accuracy: 0.7386 - loss: 1.3821\n",
      "Epoch 2: val_loss improved from 1.43414 to 0.77413, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 76ms/step - categorical_accuracy: 0.7387 - loss: 1.3816 - val_categorical_accuracy: 0.8988 - val_loss: 0.7741 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.8507 - loss: 0.9071\n",
      "Epoch 3: val_loss improved from 0.77413 to 0.54703, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.8507 - loss: 0.9070 - val_categorical_accuracy: 0.9355 - val_loss: 0.5470 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - categorical_accuracy: 0.8771 - loss: 0.7332\n",
      "Epoch 4: val_loss improved from 0.54703 to 0.45050, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 75ms/step - categorical_accuracy: 0.8771 - loss: 0.7331 - val_categorical_accuracy: 0.9553 - val_loss: 0.4505 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.8915 - loss: 0.6368\n",
      "Epoch 5: val_loss did not improve from 0.45050\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.8915 - loss: 0.6368 - val_categorical_accuracy: 0.9345 - val_loss: 0.4905 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9059 - loss: 0.6102\n",
      "Epoch 6: val_loss did not improve from 0.45050\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 73ms/step - categorical_accuracy: 0.9059 - loss: 0.6101 - val_categorical_accuracy: 0.9447 - val_loss: 0.4546 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - categorical_accuracy: 0.9146 - loss: 0.5726\n",
      "Epoch 7: val_loss improved from 0.45050 to 0.39023, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.9146 - loss: 0.5726 - val_categorical_accuracy: 0.9656 - val_loss: 0.3902 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9223 - loss: 0.5311\n",
      "Epoch 8: val_loss did not improve from 0.39023\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9223 - loss: 0.5311 - val_categorical_accuracy: 0.9591 - val_loss: 0.4157 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - categorical_accuracy: 0.9233 - loss: 0.5451\n",
      "Epoch 9: val_loss did not improve from 0.39023\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 75ms/step - categorical_accuracy: 0.9233 - loss: 0.5451 - val_categorical_accuracy: 0.9629 - val_loss: 0.4319 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - categorical_accuracy: 0.9256 - loss: 0.5421\n",
      "Epoch 10: val_loss improved from 0.39023 to 0.37147, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 72ms/step - categorical_accuracy: 0.9256 - loss: 0.5421 - val_categorical_accuracy: 0.9701 - val_loss: 0.3715 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - categorical_accuracy: 0.9322 - loss: 0.5005\n",
      "Epoch 11: val_loss improved from 0.37147 to 0.35864, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 71ms/step - categorical_accuracy: 0.9322 - loss: 0.5005 - val_categorical_accuracy: 0.9796 - val_loss: 0.3586 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9299 - loss: 0.5153\n",
      "Epoch 12: val_loss did not improve from 0.35864\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.9299 - loss: 0.5153 - val_categorical_accuracy: 0.9760 - val_loss: 0.3614 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9363 - loss: 0.5009\n",
      "Epoch 13: val_loss improved from 0.35864 to 0.34704, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 69ms/step - categorical_accuracy: 0.9363 - loss: 0.5009 - val_categorical_accuracy: 0.9811 - val_loss: 0.3470 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9406 - loss: 0.4745\n",
      "Epoch 14: val_loss improved from 0.34704 to 0.34419, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 73ms/step - categorical_accuracy: 0.9406 - loss: 0.4745 - val_categorical_accuracy: 0.9837 - val_loss: 0.3442 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - categorical_accuracy: 0.9302 - loss: 0.5181\n",
      "Epoch 15: val_loss did not improve from 0.34419\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 71ms/step - categorical_accuracy: 0.9302 - loss: 0.5181 - val_categorical_accuracy: 0.9746 - val_loss: 0.3675 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - categorical_accuracy: 0.9423 - loss: 0.4849\n",
      "Epoch 16: val_loss did not improve from 0.34419\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 67ms/step - categorical_accuracy: 0.9423 - loss: 0.4849 - val_categorical_accuracy: 0.9745 - val_loss: 0.3577 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9435 - loss: 0.4691\n",
      "Epoch 17: val_loss improved from 0.34419 to 0.32837, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 70ms/step - categorical_accuracy: 0.9435 - loss: 0.4691 - val_categorical_accuracy: 0.9803 - val_loss: 0.3284 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9409 - loss: 0.4606\n",
      "Epoch 18: val_loss did not improve from 0.32837\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 70ms/step - categorical_accuracy: 0.9409 - loss: 0.4606 - val_categorical_accuracy: 0.9813 - val_loss: 0.3422 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9471 - loss: 0.4556\n",
      "Epoch 19: val_loss did not improve from 0.32837\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.9471 - loss: 0.4556 - val_categorical_accuracy: 0.9745 - val_loss: 0.3342 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - categorical_accuracy: 0.9497 - loss: 0.4173\n",
      "Epoch 20: val_loss improved from 0.32837 to 0.31128, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 71ms/step - categorical_accuracy: 0.9497 - loss: 0.4174 - val_categorical_accuracy: 0.9822 - val_loss: 0.3113 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9494 - loss: 0.4312\n",
      "Epoch 21: val_loss improved from 0.31128 to 0.30601, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9494 - loss: 0.4312 - val_categorical_accuracy: 0.9849 - val_loss: 0.3060 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9472 - loss: 0.4362\n",
      "Epoch 22: val_loss did not improve from 0.30601\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9472 - loss: 0.4362 - val_categorical_accuracy: 0.9765 - val_loss: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9495 - loss: 0.4171\n",
      "Epoch 23: val_loss did not improve from 0.30601\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 69ms/step - categorical_accuracy: 0.9495 - loss: 0.4172 - val_categorical_accuracy: 0.9813 - val_loss: 0.3364 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9467 - loss: 0.4365\n",
      "Epoch 24: val_loss did not improve from 0.30601\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9467 - loss: 0.4365 - val_categorical_accuracy: 0.9849 - val_loss: 0.3109 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9642 - loss: 0.3812\n",
      "Epoch 25: val_loss improved from 0.30601 to 0.26356, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 67ms/step - categorical_accuracy: 0.9642 - loss: 0.3811 - val_categorical_accuracy: 0.9924 - val_loss: 0.2636 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9717 - loss: 0.3286\n",
      "Epoch 26: val_loss improved from 0.26356 to 0.23443, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.9717 - loss: 0.3285 - val_categorical_accuracy: 0.9943 - val_loss: 0.2344 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9720 - loss: 0.2971\n",
      "Epoch 27: val_loss improved from 0.23443 to 0.20900, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9720 - loss: 0.2971 - val_categorical_accuracy: 0.9943 - val_loss: 0.2090 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9753 - loss: 0.2653\n",
      "Epoch 28: val_loss improved from 0.20900 to 0.18429, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 69ms/step - categorical_accuracy: 0.9753 - loss: 0.2653 - val_categorical_accuracy: 0.9949 - val_loss: 0.1843 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9773 - loss: 0.2392\n",
      "Epoch 29: val_loss improved from 0.18429 to 0.16464, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 68ms/step - categorical_accuracy: 0.9773 - loss: 0.2392 - val_categorical_accuracy: 0.9943 - val_loss: 0.1646 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9812 - loss: 0.2059\n",
      "Epoch 30: val_loss improved from 0.16464 to 0.14676, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9812 - loss: 0.2058 - val_categorical_accuracy: 0.9947 - val_loss: 0.1468 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9818 - loss: 0.1919\n",
      "Epoch 31: val_loss improved from 0.14676 to 0.12866, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 69ms/step - categorical_accuracy: 0.9818 - loss: 0.1919 - val_categorical_accuracy: 0.9962 - val_loss: 0.1287 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9828 - loss: 0.1730\n",
      "Epoch 32: val_loss improved from 0.12866 to 0.11502, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 67ms/step - categorical_accuracy: 0.9828 - loss: 0.1730 - val_categorical_accuracy: 0.9968 - val_loss: 0.1150 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9784 - loss: 0.1696\n",
      "Epoch 33: val_loss improved from 0.11502 to 0.10662, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9784 - loss: 0.1696 - val_categorical_accuracy: 0.9955 - val_loss: 0.1066 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9850 - loss: 0.1429\n",
      "Epoch 34: val_loss improved from 0.10662 to 0.09712, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - categorical_accuracy: 0.9850 - loss: 0.1429 - val_categorical_accuracy: 0.9958 - val_loss: 0.0971 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.9832 - loss: 0.1358\n",
      "Epoch 35: val_loss improved from 0.09712 to 0.08768, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 70ms/step - categorical_accuracy: 0.9832 - loss: 0.1358 - val_categorical_accuracy: 0.9972 - val_loss: 0.0877 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - categorical_accuracy: 0.9836 - loss: 0.1348\n",
      "Epoch 36: val_loss improved from 0.08768 to 0.08177, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 72ms/step - categorical_accuracy: 0.9836 - loss: 0.1348 - val_categorical_accuracy: 0.9972 - val_loss: 0.0818 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - categorical_accuracy: 0.9835 - loss: 0.1244\n",
      "Epoch 37: val_loss improved from 0.08177 to 0.07603, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 77ms/step - categorical_accuracy: 0.9835 - loss: 0.1244 - val_categorical_accuracy: 0.9970 - val_loss: 0.0760 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - categorical_accuracy: 0.9830 - loss: 0.1224\n",
      "Epoch 38: val_loss improved from 0.07603 to 0.07070, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 76ms/step - categorical_accuracy: 0.9830 - loss: 0.1224 - val_categorical_accuracy: 0.9974 - val_loss: 0.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - categorical_accuracy: 0.9830 - loss: 0.1173\n",
      "Epoch 39: val_loss improved from 0.07070 to 0.06875, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 87ms/step - categorical_accuracy: 0.9830 - loss: 0.1173 - val_categorical_accuracy: 0.9968 - val_loss: 0.0687 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - categorical_accuracy: 0.9839 - loss: 0.1127\n",
      "Epoch 40: val_loss improved from 0.06875 to 0.06337, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 81ms/step - categorical_accuracy: 0.9839 - loss: 0.1127 - val_categorical_accuracy: 0.9974 - val_loss: 0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - categorical_accuracy: 0.9839 - loss: 0.1086\n",
      "Epoch 41: val_loss improved from 0.06337 to 0.05984, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 76ms/step - categorical_accuracy: 0.9839 - loss: 0.1086 - val_categorical_accuracy: 0.9979 - val_loss: 0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - categorical_accuracy: 0.9859 - loss: 0.1036\n",
      "Epoch 42: val_loss improved from 0.05984 to 0.05721, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 81ms/step - categorical_accuracy: 0.9859 - loss: 0.1036 - val_categorical_accuracy: 0.9977 - val_loss: 0.0572 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9858 - loss: 0.0948\n",
      "Epoch 43: val_loss improved from 0.05721 to 0.05428, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 73ms/step - categorical_accuracy: 0.9858 - loss: 0.0948 - val_categorical_accuracy: 0.9985 - val_loss: 0.0543 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - categorical_accuracy: 0.9854 - loss: 0.0945\n",
      "Epoch 44: val_loss did not improve from 0.05428\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 74ms/step - categorical_accuracy: 0.9854 - loss: 0.0945 - val_categorical_accuracy: 0.9975 - val_loss: 0.0543 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - categorical_accuracy: 0.9834 - loss: 0.0978\n",
      "Epoch 45: val_loss improved from 0.05428 to 0.05195, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 76ms/step - categorical_accuracy: 0.9834 - loss: 0.0978 - val_categorical_accuracy: 0.9983 - val_loss: 0.0519 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9827 - loss: 0.0993\n",
      "Epoch 46: val_loss improved from 0.05195 to 0.05074, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 74ms/step - categorical_accuracy: 0.9827 - loss: 0.0993 - val_categorical_accuracy: 0.9975 - val_loss: 0.0507 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - categorical_accuracy: 0.9845 - loss: 0.0936\n",
      "Epoch 47: val_loss improved from 0.05074 to 0.04870, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 74ms/step - categorical_accuracy: 0.9845 - loss: 0.0936 - val_categorical_accuracy: 0.9989 - val_loss: 0.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - categorical_accuracy: 0.9855 - loss: 0.0879\n",
      "Epoch 48: val_loss improved from 0.04870 to 0.04830, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 73ms/step - categorical_accuracy: 0.9855 - loss: 0.0879 - val_categorical_accuracy: 0.9974 - val_loss: 0.0483 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9874 - loss: 0.0810\n",
      "Epoch 49: val_loss did not improve from 0.04830\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 72ms/step - categorical_accuracy: 0.9874 - loss: 0.0810 - val_categorical_accuracy: 0.9962 - val_loss: 0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - categorical_accuracy: 0.9864 - loss: 0.0839\n",
      "Epoch 50: val_loss improved from 0.04830 to 0.04656, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 75ms/step - categorical_accuracy: 0.9864 - loss: 0.0839 - val_categorical_accuracy: 0.9977 - val_loss: 0.0466 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - categorical_accuracy: 0.9852 - loss: 0.0879\n",
      "Epoch 51: val_loss improved from 0.04656 to 0.04498, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 72ms/step - categorical_accuracy: 0.9852 - loss: 0.0879 - val_categorical_accuracy: 0.9972 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m660/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - categorical_accuracy: 0.9866 - loss: 0.0810\n",
      "Epoch 52: val_loss improved from 0.04498 to 0.04404, saving model to models/best_model.keras\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 72ms/step - categorical_accuracy: 0.9866 - loss: 0.0810 - val_categorical_accuracy: 0.9981 - val_loss: 0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m653/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - categorical_accuracy: 0.9861 - loss: 0.0821\n",
      "Epoch 53: val_loss did not improve from 0.04404\n",
      "\u001b[1m661/661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - categorical_accuracy: 0.9861 - loss: 0.0821 - val_categorical_accuracy: 0.9975 - val_loss: 0.0445 - learning_rate: 1.0000e-04\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 - 1s - 8ms/step - categorical_accuracy: 0.9985 - loss: 0.0543\n",
      "Final loss: 0.05\n",
      "Final accuracy: 99.85%\n"
     ]
    }
   ],
   "source": [
    "def main(data_dir, model_path):\n",
    "    \"\"\"\n",
    "    Main function to load data, preprocess it, train a model, and evaluate the results.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing the dataset.\n",
    "    model_path (str): Path to save the trained model.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the data\n",
    "    images, labels = load_and_preprocess_data(data_dir)\n",
    "    \n",
    "    # Check if images or labels are empty\n",
    "    if len(images) == 0 or len(labels) == 0:\n",
    "        print(\"No images or labels found. Please check the data directory.\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    # # == Convert labels to one-hot vectors\n",
    "    # labels = tf.keras.utils.to_categorical(labels, NUM_CATEGORIES)\n",
    "\n",
    "    # # Split data into training and testing sets (non-stratified)\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(\n",
    "    #     np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    # )\n",
    "    # # ==\n",
    "    \n",
    "    \n",
    "    # === Perform stratified split to maintain the proportion of each class in both training and test sets\n",
    "    # Using random_state=32 for reproducibility\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE, stratify=labels, random_state=32\n",
    "    )\n",
    "\n",
    "    # Convert labels to categorical format\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CATEGORIES)\n",
    "    # ===\n",
    "\n",
    "\n",
    "    # Create an image data generator for data augmentation\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,                      # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range=0.1,                         # Randomly zoom image\n",
    "        width_shift_range=0.1,                  # Randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,                 # Randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,                   # Randomly flip images horizontally\n",
    "        vertical_flip=False,                    # Randomly flip images vertically (set to True if applicable)\n",
    "        shear_range=0.1,                        # Apply shear transformation\n",
    "        channel_shift_range=0.1,                # Randomly shift color channels\n",
    "        preprocessing_function=augment_image    # Apply the custom augmentation function -> you can see it few block up\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Get the model\n",
    "    model = get_model()\n",
    "\n",
    "    # Define callbacks for training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1\n",
    "    )\n",
    "\n",
    "    # Early stopping callback to prevent overfitting by stopping training early if the validation accuracy does not improve\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',  # Monitor the validation categorical accuracy\n",
    "        min_delta=0.001,                     # Minimum change to qualify as an improvement\n",
    "        patience=10,                         # Number of epochs with no improvement after which training will be stopped\n",
    "        mode='max',                          # Stop when the quantity monitored has stopped increasing\n",
    "        verbose=1,                           # Print messages when early stopping is triggered\n",
    "        restore_best_weights=True            # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler callback to reduce the learning rate when the validation loss plateaus\n",
    "    lr_scheduler_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',                  # Monitor the validation loss\n",
    "        factor=0.1,                          # Factor by which the learning rate will be reduced\n",
    "        patience=3,                          # Number of epochs with no improvement after which learning rate will be reduced\n",
    "        verbose=1,                           # Print messages when the learning rate is reduced\n",
    "        min_delta=0.001,                     # Minimum change to qualify as an improvement\n",
    "        cooldown=1,                          # Number of epochs to wait before resuming normal operation after the learning rate has been reduced\n",
    "        min_lr=1e-6                          # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    # Custom callback for additional functionality (defined elsewhere in the code)\n",
    "    custom_callback = CustomCallback()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=32), \n",
    "        epochs=EPOCHS, \n",
    "        validation_data=(x_test, y_test), \n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_scheduler_callback, custom_callback]\n",
    "    )\n",
    "\n",
    "    # Plot the training history\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Print the final results\n",
    "    print_final_results(model, x_test, y_test)\n",
    "\n",
    "# Call the main function with the appropriate data directory and model path\n",
    "main(data_dir, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Predictions on unseed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load images from directory: 'data/gtsrb-test-files'.\n",
      "Total images loaded: 215\n",
      "Unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 30 - Predicted class: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 29 - Predicted class: 29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 34 - Predicted class: 34\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 40 - Predicted class: 40\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 10 - Predicted class: 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 37 - Predicted class: 37\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 28 - Predicted class: 28\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 19 - Predicted class: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 38 - Predicted class: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 27 - Predicted class: 27\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 23 - Predicted class: 23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 15 - Predicted class: 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 18 - Predicted class: 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 35 - Predicted class: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 21 - Predicted class: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "True class: 26 - Predicted class: 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 12 - Predicted class: 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 4 - Predicted class: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 41 - Predicted class: 41\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 32 - Predicted class: 32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 1 - Predicted class: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 24 - Predicted class: 24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 8 - Predicted class: 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 39 - Predicted class: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 22 - Predicted class: 22\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 25 - Predicted class: 25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 6 - Predicted class: 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 17 - Predicted class: 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 13 - Predicted class: 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 3 - Predicted class: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 36 - Predicted class: 36\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 42 - Predicted class: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 5 - Predicted class: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 20 - Predicted class: 20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 0 - Predicted class: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 9 - Predicted class: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 31 - Predicted class: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 14 - Predicted class: 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "True class: 11 - Predicted class: 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 7 - Predicted class: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "True class: 2 - Predicted class: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 33 - Predicted class: 33\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "True class: 16 - Predicted class: 16\n",
      "Correct predictions: 215\n",
      "Incorrect predictions: 0\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "IMG_PREDICTIONS_PER_FOLDER = 5\n",
    "\n",
    "# Moved 5 files (each category) from the GTSRB dataset in another folder to use trained model on them to see if performs well\n",
    "data_dir = 'data/gtsrb-test-files' \n",
    "\n",
    "def load_and_preprocess_data(data_dir, num_images_per_label=1):\n",
    "    \"\"\"\n",
    "    Load images from a directory, preprocess them by resizing and normalizing, and return the images and their labels.\n",
    "    Limits the number of images per label to a specified number.\n",
    "\n",
    "    Parameters:\n",
    "    data_dir (str): Path to the directory containing subdirectories of images. Each subdirectory should be named \n",
    "                    with an integer label and contain the corresponding images.\n",
    "    num_images_per_label (int): The maximum number of images to load per label. Default is 1 (minimum).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of preprocessed images.\n",
    "    np.ndarray: Array of labels corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_count = defaultdict(int)\n",
    "\n",
    "    # Iterate over each folder in the data directory\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        \n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Convert folder name to integer label\n",
    "        label = int(folder)\n",
    "        \n",
    "        # Iterate over each file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Stop if the number of images for this label reaches the limit\n",
    "            if label_count[label] >= num_images_per_label:\n",
    "                break\n",
    "\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Check if the file is an image\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm')):\n",
    "                image = cv2.imread(file_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    # Resize the image to the desired dimensions\n",
    "                    resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    preprocessed_image = resized_image / 255.0\n",
    "                    \n",
    "                    # Append the preprocessed image and label to the lists\n",
    "                    images.append(preprocessed_image)\n",
    "                    labels.append(label)\n",
    "                    label_count[label] += 1\n",
    "\n",
    "    print(f\"Load images from directory: '{data_dir}'.\")\n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    print(f\"Unique labels: {set(labels)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load and preprocess the entire dataset with a limit of 10 images per label\n",
    "images, true_labels = load_and_preprocess_data(data_dir, num_images_per_label=IMG_PREDICTIONS_PER_FOLDER)\n",
    "\n",
    "# Initialize counters for correct and incorrect predictions\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "# Make predictions on the dataset\n",
    "for i, image in enumerate(images):\n",
    "    preprocessed_image = np.expand_dims(image, axis=0)  # Already normalized during loading\n",
    "    prediction = predict_image(model, preprocessed_image)\n",
    "    if prediction == true_labels[i]:\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        incorrect_predictions += 1\n",
    "    print(f\"True class: {true_labels[i]} - Predicted class: {prediction}\")\n",
    "\n",
    "# Print the count of correct and incorrect predictions\n",
    "total_predictions = correct_predictions + incorrect_predictions\n",
    "accuracy_percentage = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Incorrect predictions: {incorrect_predictions}\")\n",
    "print(f\"Accuracy: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
